# Text Summarization using the sequence to sequence model with the attention mechanism

In brief, the provided code represents a sequence-to-sequence (s2s) model with an attention mechanism. It leverages the t5-small model to generate summaries for input documents. Evaluation metrics, including ROUGE and METEOR scores, help us to calculate the quality of the generated summaries against benchmark summaries. This approach is a common technique in natural language processing tasks such as text summarization.

Steps to access the files:

1> First download 'train.csv' file and then go to your google drive/mydrive and upload there.
Note: The train.csv file is just a test file and not the whole data file.

2> Download the main.ipynb file and run in it your google collab 

3> You are good to go
