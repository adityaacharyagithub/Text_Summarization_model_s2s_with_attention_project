# Text Summarization using the sequence to sequence model with the attention mechanism

In brief, the provided code represents a sequence-to-sequence (s2s) model with an attention mechanism. It leverages the t5-small model to generate summaries for input documents. Evaluation metrics, including ROUGE and METEOR scores, help us to calculate the quality of the generated summaries against benchmark summaries. This approach is a common technique in natural language processing tasks such as text summarization.

Steps to access the files:
1> There are two csv files namely sampletrain.csv, first download it and then go to your google drive/mydrive and upload there.
# Note: The sampletrain,csv file is just a test file if you want to use the whole data then download the train.csv file

2> Download the main.ipynb file and run in it your google collab 

3> You are good to go
